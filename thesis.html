<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Thesis Details</title>
    <link rel="stylesheet" href="styles.css">
</head>
<body>
<header>
    <h1>Master's Thesis</h1>
    <nav>
        <a href="index.html">Back to Main Page</a>
    </nav>
</header>

<main>
    <section>
        <h2>"Learning Deception and Counter-Deception Strategies in Adversarial Settings"</h2>
        <p>
            Adversarial decision-making in multi-agent systems is a critical area of research with applications in autonomous systems, cybersecurity, and robotics. These systems require agents to navigate dynamic and competitive environments where deception, ambiguity, and resource allocation play pivotal roles. Operating with incomplete or misleading information, agents must develop strategies to optimize outcomes while mitigating adversarial risks.

Using reinforcement learning, this research uncovers strategies enabling agents to balance cooperation and competition effectively. The game modeled involves two agents: one tasked with defending resources at a true goal and the other attempting to consume these resources without knowing the true goal's location.
        </p>
        <p>
            The study examines three scenarios:
            <ul>
                <li>A simple grid world with no obstacles and two goals, exploring basic deceptive strategies.</li>
                <li>A more complex grid with obstacles, where agents manage restricted paths alongside deception and resource allocation.</li>
                <li>An advanced environment with multiple true and fake goals and numerous obstacles, requiring agents to navigate ambiguity and employ sophisticated strategies.</li>
            </ul>
        </p>
        <p>
            Key findings:
            <ul>
                <li>Deceptive strategies significantly influence agent interactions.</li>
                <li>Counter-deception mechanisms improve robustness in adversarial settings.</li>
            </ul>
        </p>

                <p>
            Key findings:
            <ul>
                <li>Deceptive strategies significantly influence agent interactions.</li>
                <li>Counter-deception mechanisms improve robustness in adversarial settings.</li>
            </ul>
        </p>
    </section>

       <section>
        <h3>References</h3>
        <ol>
                        <li>
                Violetta Rostobaya, Yue Guan, James Berneburg, Michael Dorothy, Daigo Shishika, 
                *Deception by Motion: The Eater and the Mover Game*, Published in collaboration with George Mason University and DEVCOM Army Research Laboratory, 2023. Available at :
                 <a href="https://ieeexplore.ieee.org/abstract/document/10171186" target="_blank">" Paper Link"</a>
            </li>
            <li>
                Xiaosong Lu, Howard M. Schwartz, *An Investigation of Guarding a Territory Problem in a Grid World*, 
                2010 American Control Conference, Marriott Waterfront, Baltimore, MD, USA. Available at IEEE:
                 <a href="https://ieeexplore.ieee.org/abstract/document/5530771" target="_blank">" Paper Link"</a>
            </li>
            <li>
                Chidozie V. Analikwu, Howard M. Schwartz, *Multi-Agent Learning in the Game of Guarding a Territory*, 
                International Journal of Innovative Computing, Information and Control, Volume 7, Number 1, 2011. Available at:
                <a href="http://www.ijicic.org/ijicic-130606.pdf" target="_blank">" PDF Link"</a>,
            </li>

        </ol>
    </section>
</main>

<footer>
    <p>&copy; 2025 Sai Krishna Reddy Mareddy. All rights reserved.</p>
</footer>
</body>
</html>
